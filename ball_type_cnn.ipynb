{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e79b855",
   "metadata": {},
   "source": [
    "# CNN\n",
    "For taking in a 56x56 ball and determining if it's stripe, solid, or the aim circle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7f04659f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import project\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import cv2\n",
    "import json\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "from torchvision import transforms\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "\n",
    "constants = json.load(open('constants.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "c163f7c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BallDataset(Dataset):\n",
    "    def __init__(self, root_dir, augment=False):\n",
    "        self.data = []\n",
    "        self.labels = []\n",
    "        self.augment = augment\n",
    "\n",
    "        label_map = {'stripe': 0, 'solid': 1, 'aim_circle': 2}\n",
    "        root_path = Path(root_dir)\n",
    "\n",
    "        for label_name, label_value in label_map.items():\n",
    "            folder_path = root_path / label_name\n",
    "            for fpath in folder_path.iterdir():\n",
    "                if fpath.is_file():\n",
    "                    self.data.append(fpath)\n",
    "                    self.labels.append(label_value)\n",
    "\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.ToPILImage(),\n",
    "            transforms.RandomRotation(90),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.RandomVerticalFlip(),\n",
    "            transforms.ToTensor()\n",
    "        ]) if augment else transforms.Compose([\n",
    "            transforms.ToPILImage(),\n",
    "            transforms.ToTensor()\n",
    "        ])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_np = project.preprocess_file(str(self.data[idx]), size=56, padding=0, thresh_1=(0.5,1.1), thresh_2=(0.9,1.1), close_size=2, open_size=2)\n",
    "        img = self.transform(img_np)\n",
    "        return img, self.labels[idx]\n",
    "\n",
    "# create train/val/test splits\n",
    "base_dataset = BallDataset('labeling/', augment=False)\n",
    "train_size = int(0.7 * len(base_dataset))\n",
    "val_size = int(0.15 * len(base_dataset))\n",
    "test_size = len(base_dataset) - train_size - val_size\n",
    "\n",
    "\n",
    "train_indices, val_indices, test_indices = torch.utils.data.random_split(\n",
    "    range(len(base_dataset)), [train_size, val_size, test_size],\n",
    "    generator=torch.Generator().manual_seed(42)\n",
    ")\n",
    "\n",
    "train_dataset = Subset(BallDataset('labeling/', augment=True), train_indices)\n",
    "val_dataset   = Subset(BallDataset('labeling/', augment=False), val_indices)\n",
    "test_dataset  = Subset(BallDataset('labeling/', augment=False), test_indices)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader   = DataLoader(val_dataset, batch_size=32)\n",
    "test_loader  = DataLoader(test_dataset, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bdb4454",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Epoch 1, Train Loss: 18.2815, Val Accuracy: 0.7364\n",
      "Epoch 2, Train Loss: 14.4008, Val Accuracy: 0.8062\n",
      "Epoch 3, Train Loss: 11.6120, Val Accuracy: 0.7674\n",
      "Epoch 4, Train Loss: 9.3245, Val Accuracy: 0.8372\n",
      "Epoch 5, Train Loss: 7.6244, Val Accuracy: 0.8760\n",
      "Epoch 6, Train Loss: 6.5538, Val Accuracy: 0.8992\n",
      "Epoch 7, Train Loss: 5.9217, Val Accuracy: 0.9147\n",
      "Epoch 8, Train Loss: 5.4584, Val Accuracy: 0.9147\n",
      "Epoch 9, Train Loss: 5.0896, Val Accuracy: 0.9225\n",
      "Epoch 10, Train Loss: 4.9489, Val Accuracy: 0.9302\n",
      "Epoch 11, Train Loss: 4.8195, Val Accuracy: 0.9380\n",
      "Epoch 12, Train Loss: 4.6189, Val Accuracy: 0.9457\n",
      "Epoch 13, Train Loss: 4.5088, Val Accuracy: 0.9690\n",
      "Epoch 14, Train Loss: 4.4842, Val Accuracy: 0.9380\n",
      "Epoch 15, Train Loss: 4.5051, Val Accuracy: 0.9457\n",
      "Epoch 16, Train Loss: 4.4142, Val Accuracy: 0.9535\n",
      "Epoch 17, Train Loss: 4.2550, Val Accuracy: 0.9457\n",
      "Epoch 18, Train Loss: 4.2409, Val Accuracy: 0.9457\n",
      "Epoch 19, Train Loss: 4.0861, Val Accuracy: 0.9302\n",
      "Epoch 20, Train Loss: 4.0039, Val Accuracy: 0.9380\n",
      "Epoch 21, Train Loss: 4.0335, Val Accuracy: 0.9457\n",
      "Epoch 22, Train Loss: 4.0400, Val Accuracy: 0.9457\n",
      "Epoch 23, Train Loss: 4.0440, Val Accuracy: 0.9070\n",
      "Epoch 24, Train Loss: 3.9903, Val Accuracy: 0.9380\n",
      "Epoch 25, Train Loss: 3.9652, Val Accuracy: 0.9302\n",
      "Epoch 26, Train Loss: 3.8191, Val Accuracy: 0.9457\n",
      "Epoch 27, Train Loss: 3.7965, Val Accuracy: 0.9302\n",
      "Epoch 28, Train Loss: 3.8101, Val Accuracy: 0.9302\n",
      "Epoch 29, Train Loss: 3.7419, Val Accuracy: 0.9225\n",
      "Epoch 30, Train Loss: 3.6052, Val Accuracy: 0.9380\n",
      "\n",
      "Best model was from epoch 13 with Val Accuracy: 0.9690\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "model = BallCNN().to(device)\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "\n",
    "best_val_acc = 0.0\n",
    "best_model_state = None\n",
    "best_epoch = 0\n",
    "\n",
    "for epoch in range(30):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        preds = model(images)\n",
    "        loss = loss_fn(preds, labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    # validation\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            preds = model(images)\n",
    "            predicted = preds.argmax(dim=1)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "    val_acc = correct / total\n",
    "    print(f\"Epoch {epoch+1}, Train Loss: {total_loss:.4f}, Val Accuracy: {val_acc:.4f}\")\n",
    "\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        best_model_state = model.state_dict()\n",
    "        best_epoch = epoch + 1\n",
    "\n",
    "print(f\"\\nBest model was from epoch {best_epoch} with Val Accuracy: {best_val_acc:.4f}\")\n",
    "\n",
    "model.load_state_dict(best_model_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24aafaac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.9077\n"
     ]
    }
   ],
   "source": [
    "# test accuracy\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        preds = model(images)\n",
    "        predicted = preds.argmax(dim=1)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "test_acc = correct / total\n",
    "print(f\"Test Accuracy: {test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "2b368092",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "torch.save(model.state_dict(), 'ball_type.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ac3c9a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# manually test a few images from each class\n",
    "label_names = ['stripe', 'solid', 'aim_circle']\n",
    "\n",
    "\n",
    "def test_image(model, image_path, show=True):\n",
    "    model.eval()\n",
    "    actual_label = Path(image_path).parent.name\n",
    "    original_img = Image.open(image_path) \n",
    "    img_np = project.preprocess_file(image_path, size=56, padding=0,\n",
    "                                     thresh_1=(0.5, 1.1), thresh_2=(0.9, 1.1),\n",
    "                                     close_size=2, open_size=2)\n",
    "    img = torch.tensor(img_np).unsqueeze(0).unsqueeze(0).float().to(device)  # shape: (1, 1, 56, 56)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        logits = model(img)\n",
    "        probs = F.softmax(logits, dim=1).cpu().numpy()[0]\n",
    "\n",
    "    print(\"Class probabilities:\")\n",
    "    for i, prob in enumerate(probs):\n",
    "        print(f\"  {label_names[i]:>12}: {prob:.4f}\")\n",
    "\n",
    "    if show:\n",
    "        fig, axs = plt.subplots(1, 2, figsize=(4, 2))\n",
    "        axs[0].imshow(original_img, cmap='gray')\n",
    "        axs[0].set_title(f\"Original: {image_path.split('/')[-1]}\")\n",
    "        axs[0].axis('off')\n",
    "\n",
    "        axs[1].imshow(img_np, cmap='gray')\n",
    "        axs[1].set_title(f\"Actual: {actual_label}\")\n",
    "        axs[1].axis('off')\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "for class_name in label_names:\n",
    "    folder = Path('labeling') / class_name\n",
    "    files = list(folder.glob(\"*.png\"))\n",
    "    sample_files = random.sample(files, min(3, len(files)))\n",
    "    for f in sample_files:\n",
    "        test_image(model, str(f), show=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fcdb59bf",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "PytorchStreamReader failed locating file constants.pkl: file not found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 16\u001b[0m\n\u001b[1;32m     13\u001b[0m circles, data \u001b[38;5;241m=\u001b[39m project\u001b[38;5;241m.\u001b[39mgenerate_data(img, use_blue\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, k_1\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2.5\u001b[39m, k_2\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.5\u001b[39m,\n\u001b[1;32m     14\u001b[0m                              min_dist\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m, canny\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m, accum\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m18\u001b[39m, min_radius\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m23\u001b[39m, max_radius\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m27\u001b[39m)\n\u001b[1;32m     15\u001b[0m circles \u001b[38;5;241m=\u001b[39m circles[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m---> 16\u001b[0m \u001b[43mproject\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlabel_balls\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcircles\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/coding/hmc/cv/pool-agent/project.py:290\u001b[0m, in \u001b[0;36mlabel_balls\u001b[0;34m(img, circles, data)\u001b[0m\n\u001b[1;32m    279\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m''' \u001b[39;00m\n\u001b[1;32m    280\u001b[0m \u001b[38;5;124;03mGiven img, circle coords, and cropped ball data, return dict with\u001b[39;00m\n\u001b[1;32m    281\u001b[0m \u001b[38;5;124;03m{\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;124;03m}\u001b[39;00m\n\u001b[1;32m    288\u001b[0m \u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m    289\u001b[0m \u001b[38;5;66;03m# load torch model 'ball_type.pth'\u001b[39;00m\n\u001b[0;32m--> 290\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjit\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mroot\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mball_type.pth\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    292\u001b[0m cue_ball \u001b[38;5;241m=\u001b[39m find_cue_ball(img, circles)\n\u001b[1;32m    293\u001b[0m eight_ball \u001b[38;5;241m=\u001b[39m find_8_ball(img, circles)\n",
      "File \u001b[0;32m~/coding/hmc/cv/pool-agent/venv/lib/python3.10/site-packages/torch/jit/_serialization.py:163\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, _extra_files, _restore_shapes)\u001b[0m\n\u001b[1;32m    161\u001b[0m cu \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39mCompilationUnit()\n\u001b[1;32m    162\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(f, (\u001b[38;5;28mstr\u001b[39m, os\u001b[38;5;241m.\u001b[39mPathLike)):\n\u001b[0;32m--> 163\u001b[0m     cpp_module \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimport_ir_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcu\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfspath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_extra_files\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_restore_shapes\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    165\u001b[0m     cpp_module \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39mimport_ir_module_from_buffer(\n\u001b[1;32m    166\u001b[0m         cu, f\u001b[38;5;241m.\u001b[39mread(), map_location, _extra_files, _restore_shapes\n\u001b[1;32m    167\u001b[0m     )  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: PytorchStreamReader failed locating file constants.pkl: file not found"
     ]
    }
   ],
   "source": [
    "# using model, show solid/stripe labels in a given table\n",
    "screenshots_dir = Path('./screenshots')\n",
    "screenshots = sorted(screenshots_dir.glob('screenshot_*.png'))\n",
    "for ss_num, screenshot in enumerate(screenshots):\n",
    "    img = cv2.imread(str(screenshot))\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    # crop image to playable area\n",
    "    img = img[constants['playable_area']['top_left'][1]:constants['playable_area']['bottom_right'][1],\n",
    "              constants['playable_area']['top_left'][0]:constants['playable_area']['bottom_right'][0]]\n",
    "    # crop image by another 5px on each side\n",
    "    img = img[15:-15, 15:-15]\n",
    "    # show image\n",
    "    circles, data = project.generate_data(img, use_blue=False, k_1=2.5, k_2=1.5,\n",
    "                                 min_dist=20, canny=100, accum=18, min_radius=23, max_radius=27)\n",
    "    circles = circles[0]\n",
    "    project.label_balls(img, circles, data)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e948bf27",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
