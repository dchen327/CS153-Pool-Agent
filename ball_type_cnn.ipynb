{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e79b855",
   "metadata": {},
   "source": [
    "# CNN\n",
    "For taking in a 56x56 ball and determining if it's stripe, solid, or the aim circle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7f04659f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import project\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "from torchvision import transforms\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "c163f7c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BallDataset(Dataset):\n",
    "    def __init__(self, root_dir, augment=False):\n",
    "        self.data = []\n",
    "        self.labels = []\n",
    "        self.augment = augment\n",
    "\n",
    "        label_map = {'stripe': 0, 'solid': 1, 'aim_circle': 2}\n",
    "        root_path = Path(root_dir)\n",
    "\n",
    "        for label_name, label_value in label_map.items():\n",
    "            folder_path = root_path / label_name\n",
    "            for fpath in folder_path.iterdir():\n",
    "                if fpath.is_file():\n",
    "                    self.data.append(fpath)\n",
    "                    self.labels.append(label_value)\n",
    "\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.ToPILImage(),\n",
    "            transforms.RandomRotation(90),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.RandomVerticalFlip(),\n",
    "            transforms.ToTensor()\n",
    "        ]) if augment else transforms.Compose([\n",
    "            transforms.ToPILImage(),\n",
    "            transforms.ToTensor()\n",
    "        ])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_np = project.preprocess_file(str(self.data[idx]), size=56, padding=0, thresh_1=(0.5,1.1), thresh_2=(0.9,1.1), close_size=2, open_size=2)\n",
    "        img = self.transform(img_np)\n",
    "        return img, self.labels[idx]\n",
    "\n",
    "# create train/val/test splits\n",
    "base_dataset = BallDataset('labeling/', augment=False)\n",
    "train_size = int(0.7 * len(base_dataset))\n",
    "val_size = int(0.15 * len(base_dataset))\n",
    "test_size = len(base_dataset) - train_size - val_size\n",
    "\n",
    "\n",
    "train_indices, val_indices, test_indices = torch.utils.data.random_split(\n",
    "    range(len(base_dataset)), [train_size, val_size, test_size],\n",
    "    generator=torch.Generator().manual_seed(42)\n",
    ")\n",
    "\n",
    "train_dataset = Subset(BallDataset('labeling/', augment=True), train_indices)\n",
    "val_dataset   = Subset(BallDataset('labeling/', augment=False), val_indices)\n",
    "test_dataset  = Subset(BallDataset('labeling/', augment=False), test_indices)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader   = DataLoader(val_dataset, batch_size=32)\n",
    "test_loader  = DataLoader(test_dataset, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bdb4454",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Epoch 1, Train Loss: 18.2815, Val Accuracy: 0.7364\n",
      "Epoch 2, Train Loss: 14.4008, Val Accuracy: 0.8062\n",
      "Epoch 3, Train Loss: 11.6120, Val Accuracy: 0.7674\n",
      "Epoch 4, Train Loss: 9.3245, Val Accuracy: 0.8372\n",
      "Epoch 5, Train Loss: 7.6244, Val Accuracy: 0.8760\n",
      "Epoch 6, Train Loss: 6.5538, Val Accuracy: 0.8992\n",
      "Epoch 7, Train Loss: 5.9217, Val Accuracy: 0.9147\n",
      "Epoch 8, Train Loss: 5.4584, Val Accuracy: 0.9147\n",
      "Epoch 9, Train Loss: 5.0896, Val Accuracy: 0.9225\n",
      "Epoch 10, Train Loss: 4.9489, Val Accuracy: 0.9302\n",
      "Epoch 11, Train Loss: 4.8195, Val Accuracy: 0.9380\n",
      "Epoch 12, Train Loss: 4.6189, Val Accuracy: 0.9457\n",
      "Epoch 13, Train Loss: 4.5088, Val Accuracy: 0.9690\n",
      "Epoch 14, Train Loss: 4.4842, Val Accuracy: 0.9380\n",
      "Epoch 15, Train Loss: 4.5051, Val Accuracy: 0.9457\n",
      "Epoch 16, Train Loss: 4.4142, Val Accuracy: 0.9535\n",
      "Epoch 17, Train Loss: 4.2550, Val Accuracy: 0.9457\n",
      "Epoch 18, Train Loss: 4.2409, Val Accuracy: 0.9457\n",
      "Epoch 19, Train Loss: 4.0861, Val Accuracy: 0.9302\n",
      "Epoch 20, Train Loss: 4.0039, Val Accuracy: 0.9380\n",
      "Epoch 21, Train Loss: 4.0335, Val Accuracy: 0.9457\n",
      "Epoch 22, Train Loss: 4.0400, Val Accuracy: 0.9457\n",
      "Epoch 23, Train Loss: 4.0440, Val Accuracy: 0.9070\n",
      "Epoch 24, Train Loss: 3.9903, Val Accuracy: 0.9380\n",
      "Epoch 25, Train Loss: 3.9652, Val Accuracy: 0.9302\n",
      "Epoch 26, Train Loss: 3.8191, Val Accuracy: 0.9457\n",
      "Epoch 27, Train Loss: 3.7965, Val Accuracy: 0.9302\n",
      "Epoch 28, Train Loss: 3.8101, Val Accuracy: 0.9302\n",
      "Epoch 29, Train Loss: 3.7419, Val Accuracy: 0.9225\n",
      "Epoch 30, Train Loss: 3.6052, Val Accuracy: 0.9380\n",
      "\n",
      "Best model was from epoch 13 with Val Accuracy: 0.9690\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class BallCNN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(1, 16, kernel_size=3, padding=1),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool2d(2),\n",
    "            torch.nn.Conv2d(16, 32, kernel_size=3, padding=1),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool2d(2),\n",
    "        )\n",
    "        self.fc = torch.nn.Sequential(\n",
    "            torch.nn.Flatten(),\n",
    "            torch.nn.Linear(32 * 14 * 14, 64),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(64, 3),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc(self.conv(x))\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "model = BallCNN().to(device)\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "\n",
    "best_val_acc = 0.0\n",
    "best_model_state = None\n",
    "best_epoch = 0\n",
    "\n",
    "for epoch in range(30):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        preds = model(images)\n",
    "        loss = loss_fn(preds, labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    # validation\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            preds = model(images)\n",
    "            predicted = preds.argmax(dim=1)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "    val_acc = correct / total\n",
    "    print(f\"Epoch {epoch+1}, Train Loss: {total_loss:.4f}, Val Accuracy: {val_acc:.4f}\")\n",
    "\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        best_model_state = model.state_dict()\n",
    "        best_epoch = epoch + 1\n",
    "\n",
    "print(f\"\\nBest model was from epoch {best_epoch} with Val Accuracy: {best_val_acc:.4f}\")\n",
    "\n",
    "model.load_state_dict(best_model_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24aafaac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.9077\n"
     ]
    }
   ],
   "source": [
    "# test accuracy\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        preds = model(images)\n",
    "        predicted = preds.argmax(dim=1)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "test_acc = correct / total\n",
    "print(f\"Test Accuracy: {test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "2b368092",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "torch.save(model.state_dict(), 'ball_type.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ac3c9a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# manually test a few images from each class\n",
    "label_names = ['stripe', 'solid', 'aim_circle']\n",
    "\n",
    "\n",
    "def test_image(model, image_path, show=True):\n",
    "    model.eval()\n",
    "    actual_label = Path(image_path).parent.name\n",
    "    original_img = Image.open(image_path) \n",
    "    img_np = project.preprocess_file(image_path, size=56, padding=0,\n",
    "                                     thresh_1=(0.5, 1.1), thresh_2=(0.9, 1.1),\n",
    "                                     close_size=2, open_size=2)\n",
    "    img = torch.tensor(img_np).unsqueeze(0).unsqueeze(0).float().to(device)  # shape: (1, 1, 56, 56)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        logits = model(img)\n",
    "        probs = F.softmax(logits, dim=1).cpu().numpy()[0]\n",
    "\n",
    "    print(\"Class probabilities:\")\n",
    "    for i, prob in enumerate(probs):\n",
    "        print(f\"  {label_names[i]:>12}: {prob:.4f}\")\n",
    "\n",
    "    if show:\n",
    "        fig, axs = plt.subplots(1, 2, figsize=(4, 2))\n",
    "        axs[0].imshow(original_img, cmap='gray')\n",
    "        axs[0].set_title(f\"Original: {image_path.split('/')[-1]}\")\n",
    "        axs[0].axis('off')\n",
    "\n",
    "        axs[1].imshow(img_np, cmap='gray')\n",
    "        axs[1].set_title(f\"Actual: {actual_label}\")\n",
    "        axs[1].axis('off')\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "for class_name in label_names:\n",
    "    folder = Path('labeling') / class_name\n",
    "    files = list(folder.glob(\"*.png\"))\n",
    "    sample_files = random.sample(files, min(3, len(files)))\n",
    "    for f in sample_files:\n",
    "        test_image(model, str(f), show=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcdb59bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using model, show solid/stripe labels in a given table\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
